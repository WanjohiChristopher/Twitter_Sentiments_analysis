{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter_Sentiments_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOqYAN3hYCRnfQ54/ZD3Ymc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WanjohiChristopher/Twitter_Sentiments_analysis/blob/master/Twitter_Sentiments_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3pjA1dqCg6c"
      },
      "source": [
        "# 1.BUSINESS UNDERSTANDING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MIQ4CYCRLZ9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1hHMV2yBnwX"
      },
      "source": [
        "# Problem Statement\n",
        "\n",
        "### Detecting the polarity of tweet sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYngEQMHBNw4"
      },
      "source": [
        "#Context\n",
        "This is the sentiment140 dataset. It contains 1000 tweets extracted using the twitter api . The tweets have been annotated (0 = negative, 4 = positive) and they can be used to detect sentiment .\n",
        "\n",
        "#description of the data\n",
        "It contains the following 6 fields:\n",
        "\n",
        "1.target: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
        "\n",
        "2.ids: The id of the tweet ( 2087)\n",
        "\n",
        "3.date: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
        "\n",
        "4.flag: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
        "\n",
        "5.user: the user that tweeted (robotickilldozr)\n",
        "\n",
        "6.text: the text of the tweet (Lyx is cool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nia-K5cHCvuz"
      },
      "source": [
        "# Data Understanding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d70ISDuhh7jy"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from functools import reduce\r\n",
        "import seaborn as sns\r\n",
        "from sklearn import preprocessing\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "import nltk \r\n",
        "import string\r\n",
        "from google.colab import files\r\n",
        "import re\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")                     #Ignoring unnecessory warnings\r\n",
        "\r\n",
        "import numpy as np                                  #for large and multi-dimensional arrays\r\n",
        "import pandas as pd                                 #for data manipulation and analysis\r\n",
        "import nltk                                         #Natural language processing tool-kit\r\n",
        "\r\n",
        "from nltk.corpus import stopwords                   #Stopwords corpus\r\n",
        "from nltk.stem import PorterStemmer                 # Stemmer\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer          #For Bag of words\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer          #For TF-IDF\r\n",
        "from gensim.models import Word2Vec       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyoLkxutDnsk"
      },
      "source": [
        "#uploading data to colab enviroment\n",
        "#upload=files.upload()\n",
        "#upload"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDW18nlhC5TE"
      },
      "source": [
        "##### importing libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "8fINIHi4D0lh",
        "outputId": "b0252e90-5a54-4b64-fa3e-8c7e5ad28e39"
      },
      "source": [
        "tweet_df=pd.read_csv('tweet.csv')\n",
        "tweet_df.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>608</th>\n",
              "      <td>4</td>\n",
              "      <td>1467965994</td>\n",
              "      <td>Mon Apr 06 23:01:56 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>lanaveenker</td>\n",
              "      <td>@AmandaEnglund Sorry to hear about your loss. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>933</th>\n",
              "      <td>0</td>\n",
              "      <td>1468039856</td>\n",
              "      <td>Mon Apr 06 23:23:51 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>georgewoods007</td>\n",
              "      <td>Yawn yawn yawn!! 10 more minutes in bed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0</td>\n",
              "      <td>1467817225</td>\n",
              "      <td>Mon Apr 06 22:21:27 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>crosland_12</td>\n",
              "      <td>@cocomix04 ill tell ya the story later  not a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>870</th>\n",
              "      <td>2</td>\n",
              "      <td>1468031172</td>\n",
              "      <td>Mon Apr 06 23:21:02 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>flashbrother</td>\n",
              "      <td>work again</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>2</td>\n",
              "      <td>1467898511</td>\n",
              "      <td>Mon Apr 06 22:42:56 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Day_Zee</td>\n",
              "      <td>@Jeffree_Star Jeffree! How do you keep your ha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     target  ...                                               text\n",
              "608       4  ...  @AmandaEnglund Sorry to hear about your loss. ...\n",
              "933       0  ...           Yawn yawn yawn!! 10 more minutes in bed \n",
              "36        0  ...  @cocomix04 ill tell ya the story later  not a ...\n",
              "870       2  ...                                        work again \n",
              "346       2  ...  @Jeffree_Star Jeffree! How do you keep your ha...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJGNk7vR1Gnb"
      },
      "source": [
        "### exploring data more"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUAKHRX_1GCx",
        "outputId": "8d54bc34-c46e-455a-d76a-bf46fc5a99a5"
      },
      "source": [
        "#info about data\r\n",
        "tweet_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   target  1000 non-null   int64 \n",
            " 1   id      1000 non-null   int64 \n",
            " 2   date    1000 non-null   object\n",
            " 3   flag    1000 non-null   object\n",
            " 4   user    1000 non-null   object\n",
            " 5   text    1000 non-null   object\n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 47.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToX1ACuH1oan",
        "outputId": "a598f05b-d18a-4cf4-88be-55cc6389af76"
      },
      "source": [
        "#checking missing values\r\n",
        "tweet_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target    0\n",
              "id        0\n",
              "date      0\n",
              "flag      0\n",
              "user      0\n",
              "text      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "EQ1CSadE1667",
        "outputId": "60167c7c-3195-41b8-f6bc-1cadc425fac1"
      },
      "source": [
        "#description of the data\r\n",
        "tweet_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1.000000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.078000</td>\n",
              "      <td>1.467936e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.323506</td>\n",
              "      <td>7.154601e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.467810e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.467875e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.467936e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.467998e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.468056e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            target            id\n",
              "count  1000.000000  1.000000e+03\n",
              "mean      2.078000  1.467936e+09\n",
              "std       1.323506  7.154601e+04\n",
              "min       0.000000  1.467810e+09\n",
              "25%       2.000000  1.467875e+09\n",
              "50%       2.000000  1.467936e+09\n",
              "75%       2.000000  1.467998e+09\n",
              "max       4.000000  1.468056e+09"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_3Nb2lC2NSY",
        "outputId": "3471cc5d-241a-491b-a8d8-e94d683ac6be"
      },
      "source": [
        "#checking taeget value counts\r\n",
        "tweet_df['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    561\n",
              "4    239\n",
              "0    200\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYEmHR_TdXbP",
        "outputId": "91f49e37-9905-4bf0-b4a6-17ebf6777867"
      },
      "source": [
        "tweet_df['id'].nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrxUT_Za3tKp",
        "outputId": "dee808de-18ab-44a3-aa23-08b5822834c5"
      },
      "source": [
        "#checking flag label value counts\r\n",
        "tweet_df['flag'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NO_QUERY    1000\n",
              "Name: flag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqjp4rDT4CEa",
        "outputId": "127c092d-5627-40c8-82e0-7dbee2b15a38"
      },
      "source": [
        "#checking user label value counts\r\n",
        "tweet_df['user'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dreaaa           3\n",
              "widyatarina      3\n",
              "atothebed        2\n",
              "EricaLeigh777    2\n",
              "AmyJade          2\n",
              "                ..\n",
              "alexleebehan     1\n",
              "TheThreePeas     1\n",
              "starkissed       1\n",
              "terrcin          1\n",
              "theresaxo        1\n",
              "Name: user, Length: 962, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc_vn1ZV5WVz",
        "outputId": "61c896a7-902d-4a81-9119-a061fd036be1"
      },
      "source": [
        "# checking dimensions of the data rows and columns\r\n",
        "tweet_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLhS8T2BXbDu"
      },
      "source": [
        "### Dropping unwanted columns\r\n",
        "\r\n",
        "we drop -flag since it is only represented as 'no query'whch might not help us -date,user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YWwN5j-W7L6"
      },
      "source": [
        "tweet_df.drop(columns=['flag','user','date'],inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "QZ0WZ8-XXUd1",
        "outputId": "ab4816af-9d60-4420-9ffd-7725ae6f7dc8"
      },
      "source": [
        "tweet_df.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>4</td>\n",
              "      <td>1467936498</td>\n",
              "      <td>@Anistorm Sorry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>4</td>\n",
              "      <td>1467947104</td>\n",
              "      <td>hates waiting for mails</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>822</th>\n",
              "      <td>0</td>\n",
              "      <td>1468013866</td>\n",
              "      <td>@kalichosich awww poor puppy is she ok?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701</th>\n",
              "      <td>2</td>\n",
              "      <td>1467986323</td>\n",
              "      <td>Re-pinging @Kyle44: Custom icons I made! =] lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>2</td>\n",
              "      <td>1467909124</td>\n",
              "      <td>Saw an ad on Craigslist for a casting call for...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     target          id                                               text\n",
              "500       4  1467936498                                   @Anistorm Sorry \n",
              "533       4  1467947104                           hates waiting for mails \n",
              "822       0  1468013866           @kalichosich awww poor puppy is she ok? \n",
              "701       2  1467986323  Re-pinging @Kyle44: Custom icons I made! =] lo...\n",
              "383       2  1467909124  Saw an ad on Craigslist for a casting call for..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2rvRSnn6lbH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhbq2hGpdL0F"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX-wA9mIYBf3"
      },
      "source": [
        " #regex expression\r\n",
        " #import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6AuaQYinWzR"
      },
      "source": [
        "# group and find the hours and minutes\n",
        "#tweet_df['text'].str.findall(r'(\\d?\\d):(\\d\\d)').sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IDaQgt4pQDt"
      },
      "source": [
        "# extract the entire time, the hours, the minutes, and the period with group names\n",
        "#tweet_df['text'].str.extractall(r'(?P<time>(?P<hour>\\d?\\d):(?P<minute>\\d\\d) ?(?P<period>[ap]m))')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCuJ7YiZ8gvR"
      },
      "source": [
        "# Data Analysis -Univariate and Bivariate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "8mTHcoouphvG",
        "outputId": "bce3b16e-d5ed-4515-c993-35ba8d1ae6ac"
      },
      "source": [
        "plt.style.use('ggplot')\r\n",
        "plt.figure(figsize=(16,8))\r\n",
        "ax = sns.countplot(x=\"target\", data=tweet_df)\r\n",
        "plt.title('Distribution of  target label')\r\n",
        "plt.xlabel('target')\r\n",
        "plt.legend()\r\n",
        "total = len(tweet_df['target'])\r\n",
        "for p in ax.patches:\r\n",
        "    width = p.get_width()\r\n",
        "    height = p.get_height()\r\n",
        "    percentage = f'{100 * p.get_height()/total:.1f}%'\r\n",
        "    x, y = p.get_xy() \r\n",
        "    ax.annotate(percentage, (x + width/2, y + height*1.02), ha='center')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOfWfw_d9IT3"
      },
      "source": [
        "From the above analysis of the target variable we can see that neutral tweets were most ,then positive whic accounts for 24% and negative tweets for 20%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UATFLZ-LEFeE"
      },
      "source": [
        "#   PREPROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnA70LzzFSXC"
      },
      "source": [
        "## A. Cleaning of Raw Data\r\n",
        "This phase involves the deletion of words or characters that do not add value to the meaning of the text. Some of the standard cleaning steps are below:\r\n",
        "\r\n",
        "    Lowering case\r\n",
        "    Removal of mentions\r\n",
        "    Removal of special characters\r\n",
        "    Removal of stopwords ##Stopwords are the words in any language which does not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence. For some search engines, these are some of the most common, short function words, such as the, is, at, which, and on\r\n",
        "    Removal of hyperlinks\r\n",
        "    Removal of numbers\r\n",
        "    Removal of whitespaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luyjR-YP9HVz",
        "outputId": "006f0464-2c9a-463d-a22f-bd859ed058e2"
      },
      "source": [
        "#overview\r\n",
        "tweet_df['text'].iloc[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1    is upset that he can't update his Facebook by ...\n",
              "2    @Kenichan I dived many times for the ball. Man...\n",
              "3      my whole body feels itchy and like its on fire \n",
              "4    @nationwideclass no, it's not behaving at all....\n",
              "5                        @Kwesidei not the whole crew \n",
              "6                                          Need a hug \n",
              "7    @LOLTrish hey  long time no see! Yes.. Rains a...\n",
              "8                 @Tatiana_K nope they didn't have it \n",
              "9                            @twittera que me muera ? \n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIFpw_fPFrvs"
      },
      "source": [
        "Lowercase letters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy1CiabQqk6i",
        "outputId": "51dcdb1e-e3f5-4a3c-83de-23e3dfbed4ac"
      },
      "source": [
        "tweet_df['text']=tweet_df['text'].str.strip().str.lower()\n",
        "tweet_df['text']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      @switchfoot http://twitpic.com/2y1zl - awww, t...\n",
              "1      is upset that he can't update his facebook by ...\n",
              "2      @kenichan i dived many times for the ball. man...\n",
              "3         my whole body feels itchy and like its on fire\n",
              "4      @nationwideclass no, it's not behaving at all....\n",
              "                             ...                        \n",
              "995    @dkoenigs thanks man.  i'm so very grateful.  ...\n",
              "996    @t_wolfe  i miss u too. i'm totally comin back...\n",
              "997    @sniffinglue ohhh. i love it. ps i'm sad we di...\n",
              "998             and somehow i still end up in this place\n",
              "999            @kisluvkis oh that is very sad, poor boy.\n",
              "Name: text, Length: 1000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ4BmwONML32"
      },
      "source": [
        "Removal of stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc12tMH_ypRB",
        "outputId": "1d362665-fe73-41ab-de4a-dae37b68bcff"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "STOPWORDS = set(stopwords.words('english'))\r\n",
        "def remove_stopwords(text):\r\n",
        "    \"\"\"custom function to remove the stopwords\"\"\"\r\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\r\n",
        "\r\n",
        "tweet_df['text']=tweet_df['text'].apply(lambda x:remove_stopwords(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6Q9TWJfMG7t",
        "outputId": "4c5d3044-4bda-41f8-bf06-ef1dad83780d"
      },
      "source": [
        " tweet_df['text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      @switchfoot http://twitpic.com/2y1zl - awww, t...\n",
              "1      upset can't update facebook texting it... migh...\n",
              "2      @kenichan dived many times ball. managed save ...\n",
              "3                       whole body feels itchy like fire\n",
              "4      @nationwideclass no, behaving all. i'm mad. he...\n",
              "                             ...                        \n",
              "995    @dkoenigs thanks man. i'm grateful. feel unwor...\n",
              "996    @t_wolfe miss u too. i'm totally comin back th...\n",
              "997      @sniffinglue ohhh. love it. ps i'm sad get hang\n",
              "998                              somehow still end place\n",
              "999                         @kisluvkis oh sad, poor boy.\n",
              "Name: text, Length: 1000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEF0JNRCOJ1y"
      },
      "source": [
        "Removal of URLs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8I22GHtMG3T"
      },
      "source": [
        "def remove_urls(text):\r\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\r\n",
        "    return url_pattern.sub(r'', text)\r\n",
        "tweet_df['text']=tweet_df['text'].apply(lambda text:remove_urls(text))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX9D4pKGMG1r",
        "outputId": "8dd858be-3837-4e6d-d8ef-23c765830d30"
      },
      "source": [
        "tweet_df['text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      @switchfoot  - awww, that's bummer. shoulda go...\n",
              "1      upset can't update facebook texting it... migh...\n",
              "2      @kenichan dived many times ball. managed save ...\n",
              "3                       whole body feels itchy like fire\n",
              "4      @nationwideclass no, behaving all. i'm mad. he...\n",
              "                             ...                        \n",
              "995    @dkoenigs thanks man. i'm grateful. feel unwor...\n",
              "996    @t_wolfe miss u too. i'm totally comin back th...\n",
              "997      @sniffinglue ohhh. love it. ps i'm sad get hang\n",
              "998                              somehow still end place\n",
              "999                         @kisluvkis oh sad, poor boy.\n",
              "Name: text, Length: 1000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ9PycNOQ31r"
      },
      "source": [
        "Removing frequent words but TFDIF Might take care of all these"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwxHDBNHMGwl",
        "outputId": "2b47d11e-aa1f-4bda-9334-58456a6073c5"
      },
      "source": [
        "#checking and counting frequent words\r\n",
        "from collections import Counter\r\n",
        "cnt = Counter()\r\n",
        "for text in tweet_df[\"text\"].values:\r\n",
        "    for word in text.split():\r\n",
        "        cnt[word] += 1\r\n",
        "        \r\n",
        "cnt.most_common(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"i'm\", 103),\n",
              " ('get', 61),\n",
              " ('like', 50),\n",
              " ('still', 42),\n",
              " ('sad', 40),\n",
              " ('go', 38),\n",
              " ('time', 38),\n",
              " ('really', 38),\n",
              " ('going', 38),\n",
              " ('-', 37)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBr8lhhBMGu5",
        "outputId": "e046c39c-89c4-496a-a02b-06beddd10229"
      },
      "source": [
        "#removing frequent words\r\n",
        "FREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\r\n",
        "def remove_freqwords(text):\r\n",
        "    \"\"\"custom function to remove the frequent words\"\"\"\r\n",
        "    return \" \".join([word for word in str(text).split() if word not in FREQWORDS])\r\n",
        "\r\n",
        "tweet_df[\"text\"] = tweet_df[\"text\"].apply(lambda text: remove_freqwords(text))\r\n",
        "tweet_df[\"text\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      @switchfoot awww, that's bummer. shoulda got d...\n",
              "1      upset can't update facebook texting it... migh...\n",
              "2      @kenichan dived many times ball. managed save ...\n",
              "3                            whole body feels itchy fire\n",
              "4      @nationwideclass no, behaving all. mad. here? ...\n",
              "                             ...                        \n",
              "995    @dkoenigs thanks man. grateful. feel unworthy ...\n",
              "996    @t_wolfe miss u too. totally comin back tho! l...\n",
              "997                  @sniffinglue ohhh. love it. ps hang\n",
              "998                                    somehow end place\n",
              "999                         @kisluvkis oh sad, poor boy.\n",
              "Name: text, Length: 1000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhHf7KCDSb5_"
      },
      "source": [
        "#Removal of Rare words-\r\n",
        "This is very intuitive, as some of the words that are very unique in nature like names, brands, product names, and some of the noise characters, such as html leftouts, also need to be removed for different NLP tasks. For example, it would be really bad to use names as a predictor for a text classification problem, even if they come out as a significant predictor. We will talk about this further in subsequent chapters. We definitely don't want all these noisy tokens to be present. We also use length of the words as a criteria for removing words with very a short length or a very long length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5dIXzWQMGm3"
      },
      "source": [
        "n_rare_words = 50\r\n",
        "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\r\n",
        "def remove_rarewords(text):\r\n",
        "    \"\"\"custom function to remove the rare words\"\"\"\r\n",
        "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])\r\n",
        "\r\n",
        "tweet_df[\"text\"] = tweet_df[\"text\"].apply(lambda text: remove_rarewords(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0h5Nf_CR4I4",
        "outputId": "8c5e7cda-a173-4347-e4df-052a568f0f87"
      },
      "source": [
        "tweet_df[\"text\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      @switchfoot awww, that's bummer. shoulda got d...\n",
              "1      upset can't update facebook texting it... migh...\n",
              "2      @kenichan dived many times ball. managed save ...\n",
              "3                            whole body feels itchy fire\n",
              "4      @nationwideclass no, behaving all. mad. here? ...\n",
              "                             ...                        \n",
              "995                                  thanks feel though,\n",
              "996                   miss u too. totally back tho! much\n",
              "997                                        love it. hang\n",
              "998                                            end place\n",
              "999                                         oh sad, poor\n",
              "Name: text, Length: 1000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD263g93bgDa"
      },
      "source": [
        "Removal of numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX8WbhwIYsU_"
      },
      "source": [
        "def remove_numbers(text):\r\n",
        "    # define the pattern to keep\r\n",
        "    pattern = r'[^a-zA-z.,!?/:;\\\"\\'\\s]' \r\n",
        "    return re.sub(pattern, '', text)\r\n",
        "\r\n",
        "tweet_df[\"text\"] = tweet_df[\"text\"].apply(lambda a:remove_numbers(a) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGlB44ZgpcOS",
        "outputId": "6fcc6858-349c-450a-a063-d230365df8a9"
      },
      "source": [
        "!pip install unicodedata2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unicodedata2 in /usr/local/lib/python3.6/dist-packages (13.0.0.post2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV30rQ4Ke-2G"
      },
      "source": [
        "#Removal of non_ascii\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "id": "xj285S9PfGb4",
        "outputId": "8ba927c2-e440-44eb-fe53-69a002355dca"
      },
      "source": [
        "'''\r\n",
        "import unicodedata2\r\n",
        "def remove_non_ascii(words):\r\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\r\n",
        "    new_words = []\r\n",
        "    for word in words:\r\n",
        "        new_word = unicodedata2.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\r\n",
        "        new_words.append(new_word)\r\n",
        "    return new_words\r\n",
        "tweet_df[\"text\"] = tweet_df[\"text\"].apply(lambda w:remove_non_ascii(w) )\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport unicodedata2\\ndef remove_non_ascii(words):\\n    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\\n    new_words = []\\n    for word in words:\\n        new_word = unicodedata2.normalize(\\'NFKD\\', word).encode(\\'ascii\\', \\'ignore\\').decode(\\'utf-8\\', \\'ignore\\')\\n        new_words.append(new_word)\\n    return new_words\\ntweet_df[\"text\"] = tweet_df[\"text\"].apply(lambda w:remove_non_ascii(w) )\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3ZZX4ndqYpq",
        "outputId": "d9df7c12-82fa-45eb-a190-4dba819c517f"
      },
      "source": [
        "tweet_df[\"text\"].sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "900    far  veiws sites put together, checking update...\n",
              "99     bad nite favorite teams: astros spartans lose....\n",
              "143    intending finish editing page novel manuscript...\n",
              "309                                          chiefdelphi\n",
              "262                   help forget th april amp; th july!\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7OQgOIkcfGk"
      },
      "source": [
        "Spelling correction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKS21XF1dyRa",
        "outputId": "f82eaf70-34b1-4c1d-db5f-488e81ac71b2"
      },
      "source": [
        "!pip install pyspellchecker"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.6/dist-packages (0.5.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "ReTPiwZLYsGx",
        "outputId": "8e050e68-8180-4b27-ff54-99780291039f"
      },
      "source": [
        "'''\r\n",
        "from spellchecker import SpellChecker\r\n",
        "\r\n",
        "spell = SpellChecker()\r\n",
        "def correct_spellings(text):\r\n",
        "    corrected_text = []\r\n",
        "    misspelled_words = spell.unknown(text.split())\r\n",
        "    for word in text.split():\r\n",
        "        if word in misspelled_words:\r\n",
        "            corrected_text.append(spell.correction(word))\r\n",
        "        else:\r\n",
        "            corrected_text.append(word)\r\n",
        "    return \" \".join(corrected_text)\r\n",
        "        \r\n",
        "\r\n",
        "\r\n",
        "tweet_df[\"text\"] = tweet_df[\"text\"].apply(lambda b:correct_spellings(b))\r\n",
        "tweet_df[\"text\"].sample(5)\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom spellchecker import SpellChecker\\n\\nspell = SpellChecker()\\ndef correct_spellings(text):\\n    corrected_text = []\\n    misspelled_words = spell.unknown(text.split())\\n    for word in text.split():\\n        if word in misspelled_words:\\n            corrected_text.append(spell.correction(word))\\n        else:\\n            corrected_text.append(word)\\n    return \" \".join(corrected_text)\\n        \\n\\n\\ntweet_df[\"text\"] = tweet_df[\"text\"].apply(lambda b:correct_spellings(b))\\ntweet_df[\"text\"].sample(5)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcdeOKeUDVDt"
      },
      "source": [
        "https://www.geeksforgeeks.org/python-lemmatization-approaches-with-examples/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBUfsGXXKmGr"
      },
      "source": [
        "#Let's practice spelling and word harmonization\r\n",
        "from textblob import TextBlob\r\n",
        "tweet_df['text']=tweet_df['text'].apply(lambda x: str(TextBlob(x).correct()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZTd8M03R4Ea",
        "outputId": "d739624d-b782-415b-894b-c12d06324f88"
      },
      "source": [
        "tweet_df[\"text\"].sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79     wonders someone u much make unhappy split seco...\n",
              "2      kenichan dived many times ball. managed save  ...\n",
              "586              daniel english professor would ashamed.\n",
              "269                                 aaaaand nausea back.\n",
              "882    worked heart today, doubling weight station. r...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxhBNqImDzft"
      },
      "source": [
        "#Tokenization\r\n",
        "Tokenization is the process of splitting text into smaller chunks, called tokens. Each token is an input to the machine learning algorithm as a feature. NLTK (Natural Language Toolkit) provides a utility function for tokenizing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FnYRBx4R4AG",
        "outputId": "25271b7b-0145-4206-e276-beac3090c189"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "tweet_df['text'] = tweet_df['text'].apply(word_tokenize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL7gAC2tR38D",
        "outputId": "055ad82f-83df-4b2e-d907-0b43874d14dd"
      },
      "source": [
        "tweet_df[\"text\"].sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "740                [stephenkruiser, sorry, hear, dog, .]\n",
              "209           [twist, think, want, read, books, library]\n",
              "783    [heidimontag, wish, would, rest, world, ., unf...\n",
              "540    [lymph, nodes, massive, ram, manual, 's, balls...\n",
              "116       [hibanick, yeah, a, know, went, stand, chance]\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwzoB5ptGBkn"
      },
      "source": [
        "# Stemming\r\n",
        "Stemming is the process of removing and replacing suffixes from a token to obtain the root or base form of the word. This is called a stem. For example, the stem for the words, satisfied, satisfaction, and satisfying is satisfy and all of these imply the same feeling.\r\n",
        "\r\n",
        "Porter stemmer is a widely used stemming technique. nltk.stem provides the utility function to stem PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "y56tcplGGExQ",
        "outputId": "7851125e-bfc9-4377-bedc-77e0b0a45feb"
      },
      "source": [
        "'''\r\n",
        "from nltk.stem.porter import PorterStemmer\r\n",
        "\r\n",
        "stemmer = PorterStemmer()\r\n",
        "def stem_words(text):\r\n",
        "    return \" \".join([stemmer.stem(word) for word in text.split()])\r\n",
        "\r\n",
        "tweet_df[\"text\"] = tweet_df[\"text\"].apply(lambda text: stem_words(text))\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom nltk.stem.porter import PorterStemmer\\n\\nstemmer = PorterStemmer()\\ndef stem_words(text):\\n    return \" \".join([stemmer.stem(word) for word in text.split()])\\n\\ntweet_df[\"text\"] = tweet_df[\"text\"].apply(lambda text: stem_words(text))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCIrS6mkHy9B"
      },
      "source": [
        "#Lemmatization\r\n",
        "Lemmatization is similar to stemming in reducing inflected words to their word stem but differs in the way that it makes sure the root word (also called as lemma) belongs to the language.\r\n",
        "\r\n",
        "As a result, this one is generally slower than stemming process. So depending on the speed requirement, we can choose to use either stemming or lemmatization.\r\n",
        "\r\n",
        "Let us use the WordNetLemmatizer in nltk to lemmatize our sentences\r\n",
        "\r\n",
        "\r\n",
        "One major difference with stemming is that lemmatize takes a part of speech parameter, pos If not supplied, the default is noun."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-a7j64SH1Pw",
        "outputId": "11bdd3bc-22e9-486d-bfa3-95540d3cfbba"
      },
      "source": [
        "\r\n",
        "import nltk\r\n",
        "nltk.download('wordnet')\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "#instantiate initializer\r\n",
        "lemmatizer = WordNetLemmatizer()\r\n",
        "def lemmatize_words(text):\r\n",
        "  # v for verb and a for noun\r\n",
        "  lem=[lemmatizer.lemmatize(i,pos='v') for i in text]\r\n",
        "  return lem\r\n",
        "\r\n",
        "tweet_df['text']=tweet_df['text'].apply(lambda y:lemmatize_words(y))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrxsQ9R0IQg1",
        "outputId": "06b514a4-e788-4994-a17c-f0b4c0ab1394"
      },
      "source": [
        "tweet_df[\"text\"].sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "994                                              [happy]\n",
              "311     [play, game, home, !, new, boss, call, yet, ...]\n",
              "565                              [in, soon, cold, right]\n",
              "438              [it, 'll, take, days, sister, passport]\n",
              "79     [wonder, someone, u, much, make, unhappy, spli...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6If-X5ub9EDx"
      },
      "source": [
        "#Removing of punctuations\r\n",
        "Punctuation removal might be a good step, when punctuation does not brings additional value for text vectorization. Punctuation removal is better to be done after the tokenization step, doing it before might cause undesirable effects. Good choice for TF-IDF, Count, Binary vectorization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GN65Xn99MMM",
        "outputId": "bb5c8aeb-e45d-4943-df41-75bd272d5e54"
      },
      "source": [
        "def remove_punctuation(text):\r\n",
        "    no_punct=\" \".join([c for c in text if c not in string.punctuation])\r\n",
        "    return no_punct\r\n",
        "tweet_df['text']=tweet_df['text'].apply(lambda x: remove_punctuation(x))\r\n",
        "tweet_df[\"text\"].sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "224    miss twitter phone break use stupid nikita pho...\n",
              "291                                      afraid bad code\n",
              "693                    d_castillo ugh that 's disconcert\n",
              "333                                  michigan state make\n",
              "103                                 watch quit housequot\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e75n4aLFxoN"
      },
      "source": [
        "Removal of whitespace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiQWC272FqVX",
        "outputId": "c7183e23-2b56-426b-fc57-16f7194a1491"
      },
      "source": [
        "def remove_whitespace(word):\r\n",
        "    result = word.strip()\r\n",
        "    return result\r\n",
        "tweet_df[\"text\"] = tweet_df[\"text\"].apply(lambda te: remove_whitespace(te))\r\n",
        "tweet_df[\"text\"].sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "196                                                 want\n",
              "902       org hill love money www think beck buckwild go\n",
              "744                         stephenkruiser www sad sorry\n",
              "572                               struggle hard inventor\n",
              "275    treat nearly day post webster tonight hopefull...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqev4xVIIyi0"
      },
      "source": [
        "## Word Embedding\r\n",
        "Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "hxFaWR5VIQTQ",
        "outputId": "eadde62f-ad3a-4977-866e-285a04cc2812"
      },
      "source": [
        "'''\r\n",
        "import gensim\r\n",
        "\r\n",
        "\r\n",
        "   \r\n",
        "#custom data is fed to machine for further processing\r\n",
        "tweet_df['text']=gensim.models.Word2Vec(tweet_df['text'], min_count = 1, size = 100, window = 5) \r\n",
        "\r\n",
        "tweet_df['text']\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nimport gensim\\n\\n\\n   \\n#custom data is fed to machine for further processing\\ntweet_df['text']=gensim.models.Word2Vec(tweet_df['text'], min_count = 1, size = 100, window = 5) \\n\\ntweet_df['text']\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ2ZYuVTZVul"
      },
      "source": [
        "##defining target variable and  predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvVUtY54ZiGu"
      },
      "source": [
        "X=tweet_df['text']\r\n",
        "y=tweet_df['target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKTW7S9bZH6n"
      },
      "source": [
        "###Extracting Features from Cleaned Tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW5NmP91aVwU",
        "outputId": "e15e843a-c09b-4979-cd8a-65d2c191ec7c"
      },
      "source": [
        "'''\r\n",
        "Now at this stage we need to apply TfidfVectorizer to make the sparse matrix to X\r\n",
        "using TF-DiF model\r\n",
        "'''\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\r\n",
        "VecModel = TfidfVectorizer()\r\n",
        "X = VecModel.fit_transform(X)\r\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1000x2449 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 7092 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh1xhrAVGNwF"
      },
      "source": [
        "#Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj-yYbN5i3QA"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "#Now we split the dataset into train and test sets\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=402)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTu6Qh6MfDYZ",
        "outputId": "79ed6f40-0667-4199-a864-ddccdbd18712"
      },
      "source": [
        "print('X_train shape is ' , X_train.shape)\r\n",
        "print('X_test shape is ' , X_test.shape)\r\n",
        "print('y_train shape is ' , y_train.shape)\r\n",
        "print('y_test shape is ' , y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape is  (750, 2449)\n",
            "X_test shape is  (250, 2449)\n",
            "y_train shape is  (750,)\n",
            "y_test shape is  (250,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro0hG42vf-3h"
      },
      "source": [
        "#Applying Classification Machine Learning ModelS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE3Koma-fOKO"
      },
      "source": [
        "#importing classfication algorithms to be applied\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.naive_bayes import  MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xctut6DkTHG"
      },
      "source": [
        "#####Logistic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6-9VCjNkXBm"
      },
      "source": [
        "Log=LogisticRegression(solver='saga', random_state=5,max_iter=500,n_jobs=-1)\r\n",
        "Log.fit(X_train,y_train)\r\n",
        "pred=Log.predict(X_test)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5AMUMuHrpkd",
        "outputId": "95ce3093-28ce-4ec9-a9a1-6932247f1bca"
      },
      "source": [
        "# model evaluation\r\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\r\n",
        "print(accuracy_score(pred, y_test))\r\n",
        "print(confusion_matrix(y_test,pred))\r\n",
        "print(classification_report(y_test,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.524\n",
            "[[  0  44   1]\n",
            " [  2 130   2]\n",
            " [  2  68   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        45\n",
            "           2       0.54      0.97      0.69       134\n",
            "           4       0.25      0.01      0.03        71\n",
            "\n",
            "    accuracy                           0.52       250\n",
            "   macro avg       0.26      0.33      0.24       250\n",
            "weighted avg       0.36      0.52      0.38       250\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpgZvEAouPqE"
      },
      "source": [
        "#other models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPvdHcqHtADt",
        "outputId": "eae1605e-b921-4045-b3ac-0a2ed1ccc667"
      },
      "source": [
        "# importing our machine learning algorithms  \r\n",
        "from sklearn.tree import DecisionTreeClassifier    \r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "\r\n",
        "# instantiating our algorithms\r\n",
        "decision_classifier = DecisionTreeClassifier()\r\n",
        "random_forest_classifier = RandomForestClassifier()\r\n",
        "gbm_classifier = GradientBoostingClassifier()\r\n",
        "\r\n",
        "# training our models\r\n",
        "decision_classifier.fit(X_train, y_train)\r\n",
        "random_forest_classifier.fit(X_train, y_train)\r\n",
        "gbm_classifier.fit(X_train, y_train)\r\n",
        "\r\n",
        "# making predictions\r\n",
        "decision_y_prediction = decision_classifier.predict(X_test) \r\n",
        "random_forest_y_pred = random_forest_classifier.predict(X_test)\r\n",
        "gbm_y_pred = gbm_classifier.predict(X_test)\r\n",
        "\r\n",
        "# evaluation metrics\r\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\r\n",
        "print('Decision Tree')\r\n",
        "print(accuracy_score(decision_y_prediction, y_test))\r\n",
        "print(confusion_matrix(decision_y_prediction, y_test))\r\n",
        "print(classification_report(decision_y_prediction, y_test))\r\n",
        "\r\n",
        "\r\n",
        "print('Random Forest')\r\n",
        "print(accuracy_score(random_forest_y_pred, y_test))\r\n",
        "print(confusion_matrix(random_forest_y_pred, y_test))\r\n",
        "print(classification_report(random_forest_y_pred, y_test))\r\n",
        "\r\n",
        "\r\n",
        "print('Gradient Boosting')\r\n",
        "print(accuracy_score(gbm_y_pred, y_test))\r\n",
        "print(confusion_matrix(gbm_y_pred, y_test))\r\n",
        "print(classification_report(gbm_y_pred, y_test))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree\n",
            "0.456\n",
            "[[ 8 24 11]\n",
            " [29 91 45]\n",
            " [ 8 19 15]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      0.19      0.18        43\n",
            "           2       0.68      0.55      0.61       165\n",
            "           4       0.21      0.36      0.27        42\n",
            "\n",
            "    accuracy                           0.46       250\n",
            "   macro avg       0.36      0.36      0.35       250\n",
            "weighted avg       0.51      0.46      0.48       250\n",
            "\n",
            "Random Forest\n",
            "0.512\n",
            "[[  2   5   5]\n",
            " [ 39 125  65]\n",
            " [  4   4   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.04      0.17      0.07        12\n",
            "           2       0.93      0.55      0.69       229\n",
            "           4       0.01      0.11      0.03         9\n",
            "\n",
            "    accuracy                           0.51       250\n",
            "   macro avg       0.33      0.27      0.26       250\n",
            "weighted avg       0.86      0.51      0.64       250\n",
            "\n",
            "Gradient Boosting\n",
            "0.508\n",
            "[[  3   7   5]\n",
            " [ 37 118  60]\n",
            " [  5   9   6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.07      0.20      0.10        15\n",
            "           2       0.88      0.55      0.68       215\n",
            "           4       0.08      0.30      0.13        20\n",
            "\n",
            "    accuracy                           0.51       250\n",
            "   macro avg       0.34      0.35      0.30       250\n",
            "weighted avg       0.77      0.51      0.60       250\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cBYTICNuygM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}